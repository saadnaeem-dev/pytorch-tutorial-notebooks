{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Our First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:32.065375Z",
     "start_time": "2023-10-23T14:58:32.048939Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up DataLoaders\n",
    "\n",
    "We'll use the built-in dataset of `torchvision.datasets.ImageFolder` to quickly set up some dataloaders of downloaded cat and fish images. \n",
    "\n",
    "`check_image`  is a quick little function that is passed to the `is_valid_file` parameter in the ImageFolder and will do a sanity check to make sure PIL can actually open the file. We're going to use this in lieu of cleaning up the downloaded dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:32.710399Z",
     "start_time": "2023-10-23T14:58:32.704320Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the transforms for every image:\n",
    "\n",
    "* Resize to 64x64\n",
    "* Convert to tensor\n",
    "* Normalize using ImageNet mean & std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:33.860698Z",
     "start_time": "2023-10-23T14:58:33.857639Z"
    }
   },
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((64,64)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:34.846556Z",
     "start_time": "2023-10-23T14:58:34.703417Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = \"../data/train/\"\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=img_transforms, is_valid_file=check_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 787\n    Root location: ../data/train/\n    StandardTransform\nTransform: Compose(\n               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:35.401584Z",
     "start_time": "2023-10-23T14:58:35.396289Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:36.605790Z",
     "start_time": "2023-10-23T14:58:36.572809Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data_path = \"../data/val/\"\n",
    "val_data = torchvision.datasets.ImageFolder(root=val_data_path,transform=img_transforms, is_valid_file=check_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 102\n    Root location: ../data/val/\n    StandardTransform\nTransform: Compose(\n               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:37.158565Z",
     "start_time": "2023-10-23T14:58:37.152524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:37.841471Z",
     "start_time": "2023-10-23T14:58:37.805829Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_path = \"../data/test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path,transform=img_transforms, is_valid_file=check_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset ImageFolder\n    Number of datapoints: 160\n    Root location: ../data/test/\n    StandardTransform\nTransform: Compose(\n               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:38.620120Z",
     "start_time": "2023-10-23T14:58:38.611004Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:39.759824Z",
     "start_time": "2023-10-23T14:58:39.753033Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:43.627804Z",
     "start_time": "2023-10-23T14:58:43.623136Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "val_data_loader  = torch.utils.data.DataLoader(val_data, batch_size=batch_size) \n",
    "test_data_loader  = torch.utils.data.DataLoader(test_data, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x15c052010>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:44.169194Z",
     "start_time": "2023-10-23T14:58:44.163236Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Model, SimpleNet\n",
    "\n",
    "SimpleNet is a very simple combination of three Linear layers and ReLu activations between them. Note that as we don't do a `softmax()` in our `forward()`, we will need to make sure we do it in our training function during the validation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:48.521235Z",
     "start_time": "2023-10-23T14:58:48.514493Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12288, 1026)\n",
    "        self.fc2 = nn.Linear(1026, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64,2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 12288)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:50.261779Z",
     "start_time": "2023-10-23T14:58:50.212479Z"
    }
   },
   "outputs": [],
   "source": [
    "simplenet = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the model to GPU\n",
    "\n",
    "Copy the model to the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.is_available()\n",
    "torch.backends.mps.is_available() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:58:53.948829Z",
     "start_time": "2023-10-23T14:58:53.939880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": "SimpleNet(\n  (fc1): Linear(in_features=12288, out_features=1026, bias=True)\n  (fc2): Linear(in_features=1026, out_features=256, bias=True)\n  (fc3): Linear(in_features=256, out_features=64, bias=True)\n  (fc4): Linear(in_features=64, out_features=2, bias=True)\n)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available() :\n",
    "    device = torch.device(\"mps\") \n",
    "    print('mps')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "simplenet.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:59:00.986769Z",
     "start_time": "2023-10-23T14:59:00.696050Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create an optimizer\n",
    "\n",
    "Here, we're just using Adam as our optimizer with a learning rate of 0.001."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(simplenet.parameters(), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:59:04.794314Z",
     "start_time": "2023-10-23T14:59:04.785090Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training \n",
    "\n",
    "Trains the model, copying batches to the GPU if required, calculating losses, optimizing the network and perform validation for each epoch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "0.002668360864040661"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2.1/len(train_data_loader.dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:59:07.735362Z",
     "start_time": "2023-10-23T14:59:07.732499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            print(f'Output Shape: {output.shape}')\n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "            print(f'F.softmax(output, dim=1): {F.softmax(output, dim=1)}')\n",
    "            print(f'torch.max(F.softmax(output, dim=1), dim=1): {torch.max(F.softmax(output, dim=1), dim=1)}')\n",
    "            print(f'torch.max(F.softmax(output, dim=1), dim=1)[1]: {torch.max(F.softmax(output, dim=1), dim=1)[1]}')\n",
    "            print(f'targets{targets}')\n",
    "            print(f'torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):{torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)}')\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:59:08.221035Z",
     "start_time": "2023-10-23T14:59:08.217747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:59:08.979146Z",
     "start_time": "2023-10-23T14:59:08.965139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:59:47.149046Z",
     "start_time": "2023-10-23T14:59:24.374512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.7359, 0.2641],\n",
      "        [0.7060, 0.2940],\n",
      "        [0.6308, 0.3692],\n",
      "        [0.6010, 0.3990],\n",
      "        [0.6318, 0.3682],\n",
      "        [0.5479, 0.4521],\n",
      "        [0.5776, 0.4224],\n",
      "        [0.6278, 0.3722],\n",
      "        [0.6686, 0.3314],\n",
      "        [0.5658, 0.4342],\n",
      "        [0.5807, 0.4193],\n",
      "        [0.4460, 0.5540],\n",
      "        [0.5721, 0.4279],\n",
      "        [0.6888, 0.3112],\n",
      "        [0.6401, 0.3599],\n",
      "        [0.5085, 0.4915],\n",
      "        [0.5705, 0.4295],\n",
      "        [0.5636, 0.4364],\n",
      "        [0.5470, 0.4530],\n",
      "        [0.7900, 0.2100],\n",
      "        [0.6888, 0.3112],\n",
      "        [0.6076, 0.3924],\n",
      "        [0.5580, 0.4420],\n",
      "        [0.4451, 0.5549],\n",
      "        [0.4898, 0.5102],\n",
      "        [0.7616, 0.2384],\n",
      "        [0.4045, 0.5955],\n",
      "        [0.6095, 0.3905],\n",
      "        [0.8587, 0.1413],\n",
      "        [0.5010, 0.4990],\n",
      "        [0.5398, 0.4602],\n",
      "        [0.8677, 0.1323],\n",
      "        [0.4833, 0.5167],\n",
      "        [0.5372, 0.4628],\n",
      "        [0.5188, 0.4812],\n",
      "        [0.7277, 0.2723],\n",
      "        [0.4778, 0.5222],\n",
      "        [0.5873, 0.4127],\n",
      "        [0.5947, 0.4053],\n",
      "        [0.6244, 0.3756],\n",
      "        [0.4777, 0.5223],\n",
      "        [0.6702, 0.3298],\n",
      "        [0.6374, 0.3626],\n",
      "        [0.6492, 0.3508],\n",
      "        [0.7002, 0.2998],\n",
      "        [0.6570, 0.3430],\n",
      "        [0.6219, 0.3781],\n",
      "        [0.7229, 0.2771],\n",
      "        [0.5496, 0.4504],\n",
      "        [0.4968, 0.5032],\n",
      "        [0.7003, 0.2997],\n",
      "        [0.5858, 0.4142],\n",
      "        [0.5641, 0.4359],\n",
      "        [0.6441, 0.3559],\n",
      "        [0.5440, 0.4560],\n",
      "        [0.4751, 0.5249],\n",
      "        [0.7051, 0.2949],\n",
      "        [0.6853, 0.3147],\n",
      "        [0.4210, 0.5790],\n",
      "        [0.7422, 0.2578],\n",
      "        [0.4790, 0.5210],\n",
      "        [0.3776, 0.6224],\n",
      "        [0.5501, 0.4499],\n",
      "        [0.6061, 0.3939]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7359, 0.7060, 0.6308, 0.6010, 0.6318, 0.5479, 0.5776, 0.6278, 0.6686,\n",
      "        0.5658, 0.5807, 0.5540, 0.5721, 0.6888, 0.6401, 0.5085, 0.5705, 0.5636,\n",
      "        0.5470, 0.7900, 0.6888, 0.6076, 0.5580, 0.5549, 0.5102, 0.7616, 0.5955,\n",
      "        0.6095, 0.8587, 0.5010, 0.5398, 0.8677, 0.5167, 0.5372, 0.5188, 0.7277,\n",
      "        0.5222, 0.5873, 0.5947, 0.6244, 0.5223, 0.6702, 0.6374, 0.6492, 0.7002,\n",
      "        0.6570, 0.6219, 0.7229, 0.5496, 0.5032, 0.7003, 0.5858, 0.5641, 0.6441,\n",
      "        0.5440, 0.5249, 0.7051, 0.6853, 0.5790, 0.7422, 0.5210, 0.6224, 0.5501,\n",
      "        0.6061], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False,  True,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.4990, 0.5010],\n",
      "        [0.5014, 0.4986],\n",
      "        [0.4565, 0.5435],\n",
      "        [0.7521, 0.2479],\n",
      "        [0.5171, 0.4829],\n",
      "        [0.6340, 0.3660],\n",
      "        [0.4486, 0.5514],\n",
      "        [0.7696, 0.2304],\n",
      "        [0.6359, 0.3641],\n",
      "        [0.6851, 0.3149],\n",
      "        [0.7822, 0.2178],\n",
      "        [0.4904, 0.5096],\n",
      "        [0.5892, 0.4108],\n",
      "        [0.6384, 0.3616],\n",
      "        [0.7688, 0.2312],\n",
      "        [0.7043, 0.2957],\n",
      "        [0.7312, 0.2688],\n",
      "        [0.5281, 0.4719],\n",
      "        [0.7280, 0.2720],\n",
      "        [0.5163, 0.4837],\n",
      "        [0.8312, 0.1688],\n",
      "        [0.4511, 0.5489],\n",
      "        [0.4539, 0.5461],\n",
      "        [0.4623, 0.5377],\n",
      "        [0.5157, 0.4843],\n",
      "        [0.4826, 0.5174],\n",
      "        [0.4242, 0.5758],\n",
      "        [0.6728, 0.3272],\n",
      "        [0.4843, 0.5157],\n",
      "        [0.4862, 0.5138],\n",
      "        [0.4494, 0.5506],\n",
      "        [0.5394, 0.4606],\n",
      "        [0.4514, 0.5486],\n",
      "        [0.4588, 0.5412],\n",
      "        [0.4469, 0.5531],\n",
      "        [0.4175, 0.5825],\n",
      "        [0.3861, 0.6139],\n",
      "        [0.4399, 0.5601]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.5010, 0.5014, 0.5435, 0.7521, 0.5171, 0.6340, 0.5514, 0.7696, 0.6359,\n",
      "        0.6851, 0.7822, 0.5096, 0.5892, 0.6384, 0.7688, 0.7043, 0.7312, 0.5281,\n",
      "        0.7280, 0.5163, 0.8312, 0.5489, 0.5461, 0.5377, 0.5157, 0.5174, 0.5758,\n",
      "        0.6728, 0.5157, 0.5138, 0.5506, 0.5394, 0.5486, 0.5412, 0.5531, 0.5825,\n",
      "        0.6139, 0.5601], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True, False,  True,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 1, Training Loss: 1.10, Validation Loss: 0.54, accuracy = 0.80\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.6190, 0.3810],\n",
      "        [0.5924, 0.4076],\n",
      "        [0.6832, 0.3168],\n",
      "        [0.5647, 0.4353],\n",
      "        [0.5280, 0.4720],\n",
      "        [0.6541, 0.3459],\n",
      "        [0.5078, 0.4922],\n",
      "        [0.5331, 0.4669],\n",
      "        [0.5700, 0.4300],\n",
      "        [0.4563, 0.5437],\n",
      "        [0.5388, 0.4612],\n",
      "        [0.3550, 0.6450],\n",
      "        [0.5367, 0.4633],\n",
      "        [0.8166, 0.1834],\n",
      "        [0.6010, 0.3990],\n",
      "        [0.4899, 0.5101],\n",
      "        [0.5081, 0.4919],\n",
      "        [0.5046, 0.4954],\n",
      "        [0.4884, 0.5116],\n",
      "        [0.9319, 0.0681],\n",
      "        [0.5636, 0.4364],\n",
      "        [0.6296, 0.3704],\n",
      "        [0.4996, 0.5004],\n",
      "        [0.3782, 0.6218],\n",
      "        [0.4452, 0.5548],\n",
      "        [0.6444, 0.3556],\n",
      "        [0.1937, 0.8063],\n",
      "        [0.5926, 0.4074],\n",
      "        [0.7464, 0.2536],\n",
      "        [0.4783, 0.5217],\n",
      "        [0.5517, 0.4483],\n",
      "        [0.7608, 0.2392],\n",
      "        [0.3907, 0.6093],\n",
      "        [0.3533, 0.6467],\n",
      "        [0.5374, 0.4626],\n",
      "        [0.6409, 0.3591],\n",
      "        [0.4500, 0.5500],\n",
      "        [0.6837, 0.3163],\n",
      "        [0.5469, 0.4531],\n",
      "        [0.5393, 0.4607],\n",
      "        [0.4034, 0.5966],\n",
      "        [0.7208, 0.2792],\n",
      "        [0.5080, 0.4920],\n",
      "        [0.6397, 0.3603],\n",
      "        [0.6036, 0.3964],\n",
      "        [0.6063, 0.3937],\n",
      "        [0.5569, 0.4431],\n",
      "        [0.6432, 0.3568],\n",
      "        [0.4908, 0.5092],\n",
      "        [0.4322, 0.5678],\n",
      "        [0.5852, 0.4148],\n",
      "        [0.3888, 0.6112],\n",
      "        [0.4998, 0.5002],\n",
      "        [0.5681, 0.4319],\n",
      "        [0.5144, 0.4856],\n",
      "        [0.4660, 0.5340],\n",
      "        [0.5795, 0.4205],\n",
      "        [0.6281, 0.3719],\n",
      "        [0.2866, 0.7134],\n",
      "        [0.6850, 0.3150],\n",
      "        [0.3740, 0.6260],\n",
      "        [0.2066, 0.7934],\n",
      "        [0.4819, 0.5181],\n",
      "        [0.5255, 0.4745]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.6190, 0.5924, 0.6832, 0.5647, 0.5280, 0.6541, 0.5078, 0.5331, 0.5700,\n",
      "        0.5437, 0.5388, 0.6450, 0.5367, 0.8166, 0.6010, 0.5101, 0.5081, 0.5046,\n",
      "        0.5116, 0.9319, 0.5636, 0.6296, 0.5004, 0.6218, 0.5548, 0.6444, 0.8063,\n",
      "        0.5926, 0.7464, 0.5217, 0.5517, 0.7608, 0.6093, 0.6467, 0.5374, 0.6409,\n",
      "        0.5500, 0.6837, 0.5469, 0.5393, 0.5966, 0.7208, 0.5080, 0.6397, 0.6036,\n",
      "        0.6063, 0.5569, 0.6432, 0.5092, 0.5678, 0.5852, 0.6112, 0.5002, 0.5681,\n",
      "        0.5144, 0.5340, 0.5795, 0.6281, 0.7134, 0.6850, 0.6260, 0.7934, 0.5181,\n",
      "        0.5255], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "         True,  True, False, False, False,  True, False,  True,  True, False,\n",
      "         True,  True, False, False,  True,  True, False,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "         True, False, False,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.3749, 0.6251],\n",
      "        [0.3890, 0.6110],\n",
      "        [0.2818, 0.7182],\n",
      "        [0.6348, 0.3652],\n",
      "        [0.4503, 0.5497],\n",
      "        [0.5944, 0.4056],\n",
      "        [0.3421, 0.6579],\n",
      "        [0.6702, 0.3298],\n",
      "        [0.5406, 0.4594],\n",
      "        [0.6944, 0.3056],\n",
      "        [0.7522, 0.2478],\n",
      "        [0.4708, 0.5292],\n",
      "        [0.5035, 0.4965],\n",
      "        [0.5468, 0.4532],\n",
      "        [0.5771, 0.4229],\n",
      "        [0.6358, 0.3642],\n",
      "        [0.6397, 0.3603],\n",
      "        [0.4101, 0.5899],\n",
      "        [0.6388, 0.3612],\n",
      "        [0.4650, 0.5350],\n",
      "        [0.7845, 0.2155],\n",
      "        [0.3247, 0.6753],\n",
      "        [0.3637, 0.6363],\n",
      "        [0.3999, 0.6001],\n",
      "        [0.4094, 0.5906],\n",
      "        [0.3930, 0.6070],\n",
      "        [0.3253, 0.6747],\n",
      "        [0.6032, 0.3968],\n",
      "        [0.4069, 0.5931],\n",
      "        [0.4184, 0.5816],\n",
      "        [0.3200, 0.6800],\n",
      "        [0.4963, 0.5037],\n",
      "        [0.2935, 0.7065],\n",
      "        [0.3773, 0.6227],\n",
      "        [0.4395, 0.5605],\n",
      "        [0.2477, 0.7523],\n",
      "        [0.1831, 0.8169],\n",
      "        [0.2987, 0.7013]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.6251, 0.6110, 0.7182, 0.6348, 0.5497, 0.5944, 0.6579, 0.6702, 0.5406,\n",
      "        0.6944, 0.7522, 0.5292, 0.5035, 0.5468, 0.5771, 0.6358, 0.6397, 0.5899,\n",
      "        0.6388, 0.5350, 0.7845, 0.6753, 0.6363, 0.6001, 0.5906, 0.6070, 0.6747,\n",
      "        0.6032, 0.5931, 0.5816, 0.6800, 0.5037, 0.7065, 0.6227, 0.5605, 0.7523,\n",
      "        0.8169, 0.7013], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False, False, False,  True, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 2, Training Loss: 0.64, Validation Loss: 0.63, accuracy = 0.69\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.7654, 0.2346],\n",
      "        [0.6889, 0.3111],\n",
      "        [0.7564, 0.2436],\n",
      "        [0.6430, 0.3570],\n",
      "        [0.5713, 0.4287],\n",
      "        [0.8191, 0.1809],\n",
      "        [0.5244, 0.4756],\n",
      "        [0.5817, 0.4183],\n",
      "        [0.6654, 0.3346],\n",
      "        [0.3825, 0.6175],\n",
      "        [0.5995, 0.4005],\n",
      "        [0.2552, 0.7448],\n",
      "        [0.5345, 0.4655],\n",
      "        [0.8761, 0.1239],\n",
      "        [0.5996, 0.4004],\n",
      "        [0.4819, 0.5181],\n",
      "        [0.5614, 0.4386],\n",
      "        [0.5419, 0.4581],\n",
      "        [0.5127, 0.4873],\n",
      "        [0.9777, 0.0223],\n",
      "        [0.6455, 0.3545],\n",
      "        [0.7124, 0.2876],\n",
      "        [0.5097, 0.4903],\n",
      "        [0.3078, 0.6922],\n",
      "        [0.4162, 0.5838],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.0724, 0.9276],\n",
      "        [0.7372, 0.2628],\n",
      "        [0.8563, 0.1437],\n",
      "        [0.5066, 0.4934],\n",
      "        [0.5776, 0.4224],\n",
      "        [0.9174, 0.0826],\n",
      "        [0.3695, 0.6305],\n",
      "        [0.2665, 0.7335],\n",
      "        [0.6124, 0.3876],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.4136, 0.5864],\n",
      "        [0.7851, 0.2149],\n",
      "        [0.6623, 0.3377],\n",
      "        [0.5791, 0.4209],\n",
      "        [0.4083, 0.5917],\n",
      "        [0.7721, 0.2279],\n",
      "        [0.5319, 0.4681],\n",
      "        [0.6447, 0.3553],\n",
      "        [0.7048, 0.2952],\n",
      "        [0.6140, 0.3860],\n",
      "        [0.6519, 0.3481],\n",
      "        [0.7346, 0.2654],\n",
      "        [0.5112, 0.4888],\n",
      "        [0.4224, 0.5776],\n",
      "        [0.6822, 0.3178],\n",
      "        [0.3096, 0.6904],\n",
      "        [0.5397, 0.4603],\n",
      "        [0.6454, 0.3546],\n",
      "        [0.5411, 0.4589],\n",
      "        [0.4303, 0.5697],\n",
      "        [0.6834, 0.3166],\n",
      "        [0.7539, 0.2461],\n",
      "        [0.2031, 0.7969],\n",
      "        [0.8483, 0.1517],\n",
      "        [0.2944, 0.7056],\n",
      "        [0.1399, 0.8601],\n",
      "        [0.4718, 0.5282],\n",
      "        [0.5712, 0.4288]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7654, 0.6889, 0.7564, 0.6430, 0.5713, 0.8191, 0.5244, 0.5817, 0.6654,\n",
      "        0.6175, 0.5995, 0.7448, 0.5345, 0.8761, 0.5996, 0.5181, 0.5614, 0.5419,\n",
      "        0.5127, 0.9777, 0.6455, 0.7124, 0.5097, 0.6922, 0.5838, 0.7930, 0.9276,\n",
      "        0.7372, 0.8563, 0.5066, 0.5776, 0.9174, 0.6305, 0.7335, 0.6124, 0.7850,\n",
      "        0.5864, 0.7851, 0.6623, 0.5791, 0.5917, 0.7721, 0.5319, 0.6447, 0.7048,\n",
      "        0.6140, 0.6519, 0.7346, 0.5112, 0.5776, 0.6822, 0.6904, 0.5397, 0.6454,\n",
      "        0.5411, 0.5697, 0.6834, 0.7539, 0.7969, 0.8483, 0.7056, 0.8601, 0.5282,\n",
      "        0.5712], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "         True,  True,  True, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True, False, False,  True,  True, False,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.2906, 0.7094],\n",
      "        [0.3983, 0.6017],\n",
      "        [0.2211, 0.7789],\n",
      "        [0.7697, 0.2303],\n",
      "        [0.4225, 0.5775],\n",
      "        [0.6104, 0.3896],\n",
      "        [0.2615, 0.7385],\n",
      "        [0.8217, 0.1783],\n",
      "        [0.5781, 0.4219],\n",
      "        [0.7930, 0.2070],\n",
      "        [0.7850, 0.2150],\n",
      "        [0.4688, 0.5312],\n",
      "        [0.5439, 0.4561],\n",
      "        [0.6377, 0.3623],\n",
      "        [0.6581, 0.3419],\n",
      "        [0.7902, 0.2098],\n",
      "        [0.7380, 0.2620],\n",
      "        [0.3602, 0.6398],\n",
      "        [0.7487, 0.2513],\n",
      "        [0.4267, 0.5733],\n",
      "        [0.7842, 0.2158],\n",
      "        [0.2481, 0.7519],\n",
      "        [0.2415, 0.7585],\n",
      "        [0.3056, 0.6944],\n",
      "        [0.3443, 0.6557],\n",
      "        [0.3376, 0.6624],\n",
      "        [0.2403, 0.7597],\n",
      "        [0.6996, 0.3004],\n",
      "        [0.3149, 0.6851],\n",
      "        [0.3874, 0.6126],\n",
      "        [0.2101, 0.7899],\n",
      "        [0.4926, 0.5074],\n",
      "        [0.1856, 0.8144],\n",
      "        [0.2852, 0.7148],\n",
      "        [0.3999, 0.6001],\n",
      "        [0.1170, 0.8830],\n",
      "        [0.0742, 0.9258],\n",
      "        [0.1582, 0.8418]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7094, 0.6017, 0.7789, 0.7697, 0.5775, 0.6104, 0.7385, 0.8217, 0.5781,\n",
      "        0.7930, 0.7850, 0.5312, 0.5439, 0.6377, 0.6581, 0.7902, 0.7380, 0.6398,\n",
      "        0.7487, 0.5733, 0.7842, 0.7519, 0.7585, 0.6944, 0.6557, 0.6624, 0.7597,\n",
      "        0.6996, 0.6851, 0.6126, 0.7899, 0.5074, 0.8144, 0.7148, 0.6001, 0.8830,\n",
      "        0.9258, 0.8418], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False, False, False,  True, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 3, Training Loss: 0.59, Validation Loss: 0.59, accuracy = 0.74\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.8067, 0.1933],\n",
      "        [0.7298, 0.2702],\n",
      "        [0.8257, 0.1743],\n",
      "        [0.6867, 0.3133],\n",
      "        [0.5993, 0.4007],\n",
      "        [0.9368, 0.0632],\n",
      "        [0.5377, 0.4623],\n",
      "        [0.6029, 0.3971],\n",
      "        [0.6609, 0.3391],\n",
      "        [0.2601, 0.7399],\n",
      "        [0.6126, 0.3874],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.5427, 0.4573],\n",
      "        [0.9273, 0.0727],\n",
      "        [0.6585, 0.3415],\n",
      "        [0.4551, 0.5449],\n",
      "        [0.5031, 0.4969],\n",
      "        [0.4690, 0.5310],\n",
      "        [0.5163, 0.4837],\n",
      "        [0.9938, 0.0062],\n",
      "        [0.5727, 0.4273],\n",
      "        [0.8015, 0.1985],\n",
      "        [0.4504, 0.5496],\n",
      "        [0.2751, 0.7249],\n",
      "        [0.3471, 0.6529],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.0359, 0.9641],\n",
      "        [0.7916, 0.2084],\n",
      "        [0.9214, 0.0786],\n",
      "        [0.5926, 0.4074],\n",
      "        [0.6269, 0.3731],\n",
      "        [0.9573, 0.0427],\n",
      "        [0.4592, 0.5408],\n",
      "        [0.3643, 0.6357],\n",
      "        [0.6789, 0.3211],\n",
      "        [0.8367, 0.1633],\n",
      "        [0.3782, 0.6218],\n",
      "        [0.8953, 0.1047],\n",
      "        [0.7651, 0.2349],\n",
      "        [0.6173, 0.3827],\n",
      "        [0.4943, 0.5057],\n",
      "        [0.8352, 0.1648],\n",
      "        [0.5485, 0.4515],\n",
      "        [0.6862, 0.3138],\n",
      "        [0.6789, 0.3211],\n",
      "        [0.6102, 0.3898],\n",
      "        [0.6777, 0.3223],\n",
      "        [0.7885, 0.2115],\n",
      "        [0.6151, 0.3849],\n",
      "        [0.4366, 0.5634],\n",
      "        [0.7039, 0.2961],\n",
      "        [0.2986, 0.7014],\n",
      "        [0.5555, 0.4445],\n",
      "        [0.6433, 0.3567],\n",
      "        [0.5148, 0.4852],\n",
      "        [0.3552, 0.6448],\n",
      "        [0.6671, 0.3329],\n",
      "        [0.8138, 0.1862],\n",
      "        [0.2409, 0.7591],\n",
      "        [0.9092, 0.0908],\n",
      "        [0.2649, 0.7351],\n",
      "        [0.2179, 0.7821],\n",
      "        [0.4219, 0.5781],\n",
      "        [0.5443, 0.4557]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.8067, 0.7298, 0.8257, 0.6867, 0.5993, 0.9368, 0.5377, 0.6029, 0.6609,\n",
      "        0.7399, 0.6126, 0.7857, 0.5427, 0.9273, 0.6585, 0.5449, 0.5031, 0.5310,\n",
      "        0.5163, 0.9938, 0.5727, 0.8015, 0.5496, 0.7249, 0.6529, 0.8300, 0.9641,\n",
      "        0.7916, 0.9214, 0.5926, 0.6269, 0.9573, 0.5408, 0.6357, 0.6789, 0.8367,\n",
      "        0.6218, 0.8953, 0.7651, 0.6173, 0.5057, 0.8352, 0.5485, 0.6862, 0.6789,\n",
      "        0.6102, 0.6777, 0.7885, 0.6151, 0.5634, 0.7039, 0.7014, 0.5555, 0.6433,\n",
      "        0.5148, 0.6448, 0.6671, 0.8138, 0.7591, 0.9092, 0.7351, 0.7821, 0.5781,\n",
      "        0.5443], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True, False, False,  True,  True, False,  True,  True,  True,\n",
      "        False,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.2788, 0.7212],\n",
      "        [0.6755, 0.3245],\n",
      "        [0.3646, 0.6354],\n",
      "        [0.7798, 0.2202],\n",
      "        [0.4171, 0.5829],\n",
      "        [0.6209, 0.3791],\n",
      "        [0.2418, 0.7582],\n",
      "        [0.8645, 0.1355],\n",
      "        [0.6078, 0.3922],\n",
      "        [0.8767, 0.1233],\n",
      "        [0.8215, 0.1785],\n",
      "        [0.4787, 0.5213],\n",
      "        [0.5346, 0.4654],\n",
      "        [0.7277, 0.2723],\n",
      "        [0.7846, 0.2154],\n",
      "        [0.8310, 0.1690],\n",
      "        [0.7833, 0.2167],\n",
      "        [0.3745, 0.6255],\n",
      "        [0.8494, 0.1506],\n",
      "        [0.4846, 0.5154],\n",
      "        [0.7900, 0.2100],\n",
      "        [0.2359, 0.7641],\n",
      "        [0.1598, 0.8402],\n",
      "        [0.2100, 0.7900],\n",
      "        [0.3888, 0.6112],\n",
      "        [0.3872, 0.6128],\n",
      "        [0.2275, 0.7725],\n",
      "        [0.7530, 0.2470],\n",
      "        [0.2250, 0.7750],\n",
      "        [0.3867, 0.6133],\n",
      "        [0.1605, 0.8395],\n",
      "        [0.5061, 0.4939],\n",
      "        [0.1636, 0.8364],\n",
      "        [0.2244, 0.7756],\n",
      "        [0.2854, 0.7146],\n",
      "        [0.0724, 0.9276],\n",
      "        [0.0463, 0.9537],\n",
      "        [0.0937, 0.9063]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7212, 0.6755, 0.6354, 0.7798, 0.5829, 0.6209, 0.7582, 0.8645, 0.6078,\n",
      "        0.8767, 0.8215, 0.5213, 0.5346, 0.7277, 0.7846, 0.8310, 0.7833, 0.6255,\n",
      "        0.8494, 0.5154, 0.7900, 0.7641, 0.8402, 0.7900, 0.6112, 0.6128, 0.7725,\n",
      "        0.7530, 0.7750, 0.6133, 0.8395, 0.5061, 0.8364, 0.7756, 0.7146, 0.9276,\n",
      "        0.9537, 0.9063], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False,  True, False,  True, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 4, Training Loss: 0.53, Validation Loss: 0.56, accuracy = 0.72\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.8453, 0.1547],\n",
      "        [0.7785, 0.2215],\n",
      "        [0.8744, 0.1256],\n",
      "        [0.7253, 0.2747],\n",
      "        [0.6415, 0.3585],\n",
      "        [0.9719, 0.0281],\n",
      "        [0.5515, 0.4485],\n",
      "        [0.6297, 0.3703],\n",
      "        [0.7106, 0.2894],\n",
      "        [0.1956, 0.8044],\n",
      "        [0.6121, 0.3879],\n",
      "        [0.1888, 0.8112],\n",
      "        [0.5956, 0.4044],\n",
      "        [0.9569, 0.0431],\n",
      "        [0.6962, 0.3038],\n",
      "        [0.4374, 0.5626],\n",
      "        [0.5113, 0.4887],\n",
      "        [0.4480, 0.5520],\n",
      "        [0.5552, 0.4448],\n",
      "        [0.9982, 0.0018],\n",
      "        [0.5776, 0.4224],\n",
      "        [0.8675, 0.1325],\n",
      "        [0.4347, 0.5653],\n",
      "        [0.2456, 0.7544],\n",
      "        [0.2971, 0.7029],\n",
      "        [0.8556, 0.1444],\n",
      "        [0.0214, 0.9786],\n",
      "        [0.8565, 0.1435],\n",
      "        [0.9584, 0.0416],\n",
      "        [0.6479, 0.3521],\n",
      "        [0.6720, 0.3280],\n",
      "        [0.9759, 0.0241],\n",
      "        [0.4914, 0.5086],\n",
      "        [0.4985, 0.5015],\n",
      "        [0.7422, 0.2578],\n",
      "        [0.8728, 0.1272],\n",
      "        [0.3450, 0.6550],\n",
      "        [0.9364, 0.0636],\n",
      "        [0.8609, 0.1391],\n",
      "        [0.6409, 0.3591],\n",
      "        [0.5467, 0.4533],\n",
      "        [0.8766, 0.1234],\n",
      "        [0.5883, 0.4117],\n",
      "        [0.7063, 0.2937],\n",
      "        [0.6744, 0.3256],\n",
      "        [0.5994, 0.4006],\n",
      "        [0.7144, 0.2856],\n",
      "        [0.8300, 0.1700],\n",
      "        [0.6919, 0.3081],\n",
      "        [0.4711, 0.5289],\n",
      "        [0.7334, 0.2666],\n",
      "        [0.3413, 0.6587],\n",
      "        [0.5825, 0.4175],\n",
      "        [0.6457, 0.3543],\n",
      "        [0.5295, 0.4705],\n",
      "        [0.3366, 0.6634],\n",
      "        [0.6757, 0.3243],\n",
      "        [0.8626, 0.1374],\n",
      "        [0.2737, 0.7263],\n",
      "        [0.9482, 0.0518],\n",
      "        [0.2465, 0.7535],\n",
      "        [0.2692, 0.7308],\n",
      "        [0.4348, 0.5652],\n",
      "        [0.5466, 0.4534]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.8453, 0.7785, 0.8744, 0.7253, 0.6415, 0.9719, 0.5515, 0.6297, 0.7106,\n",
      "        0.8044, 0.6121, 0.8112, 0.5956, 0.9569, 0.6962, 0.5626, 0.5113, 0.5520,\n",
      "        0.5552, 0.9982, 0.5776, 0.8675, 0.5653, 0.7544, 0.7029, 0.8556, 0.9786,\n",
      "        0.8565, 0.9584, 0.6479, 0.6720, 0.9759, 0.5086, 0.5015, 0.7422, 0.8728,\n",
      "        0.6550, 0.9364, 0.8609, 0.6409, 0.5467, 0.8766, 0.5883, 0.7063, 0.6744,\n",
      "        0.5994, 0.7144, 0.8300, 0.6919, 0.5289, 0.7334, 0.6587, 0.5825, 0.6457,\n",
      "        0.5295, 0.6634, 0.6757, 0.8626, 0.7263, 0.9482, 0.7535, 0.7308, 0.5652,\n",
      "        0.5466], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True, False, False,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.2895, 0.7105],\n",
      "        [0.8296, 0.1704],\n",
      "        [0.5415, 0.4585],\n",
      "        [0.7970, 0.2030],\n",
      "        [0.3981, 0.6019],\n",
      "        [0.6310, 0.3690],\n",
      "        [0.2256, 0.7744],\n",
      "        [0.8916, 0.1084],\n",
      "        [0.6375, 0.3625],\n",
      "        [0.9319, 0.0681],\n",
      "        [0.8593, 0.1407],\n",
      "        [0.4857, 0.5143],\n",
      "        [0.5831, 0.4169],\n",
      "        [0.8008, 0.1992],\n",
      "        [0.8524, 0.1476],\n",
      "        [0.8721, 0.1279],\n",
      "        [0.8202, 0.1798],\n",
      "        [0.4025, 0.5975],\n",
      "        [0.9191, 0.0809],\n",
      "        [0.5138, 0.4862],\n",
      "        [0.7727, 0.2273],\n",
      "        [0.2024, 0.7976],\n",
      "        [0.1119, 0.8881],\n",
      "        [0.1247, 0.8753],\n",
      "        [0.3931, 0.6069],\n",
      "        [0.4416, 0.5584],\n",
      "        [0.2045, 0.7955],\n",
      "        [0.7882, 0.2118],\n",
      "        [0.1866, 0.8134],\n",
      "        [0.3885, 0.6115],\n",
      "        [0.1212, 0.8788],\n",
      "        [0.5148, 0.4852],\n",
      "        [0.1304, 0.8696],\n",
      "        [0.1837, 0.8163],\n",
      "        [0.2432, 0.7568],\n",
      "        [0.0527, 0.9473],\n",
      "        [0.0309, 0.9691],\n",
      "        [0.0607, 0.9393]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7105, 0.8296, 0.5415, 0.7970, 0.6019, 0.6310, 0.7744, 0.8916, 0.6375,\n",
      "        0.9319, 0.8593, 0.5143, 0.5831, 0.8008, 0.8524, 0.8721, 0.8202, 0.5975,\n",
      "        0.9191, 0.5138, 0.7727, 0.7976, 0.8881, 0.8753, 0.6069, 0.5584, 0.7955,\n",
      "        0.7882, 0.8134, 0.6115, 0.8788, 0.5148, 0.8696, 0.8163, 0.7568, 0.9473,\n",
      "        0.9691, 0.9393], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 5, Training Loss: 0.48, Validation Loss: 0.53, accuracy = 0.75\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[8.6744e-01, 1.3256e-01],\n",
      "        [8.2031e-01, 1.7969e-01],\n",
      "        [9.0423e-01, 9.5769e-02],\n",
      "        [7.5478e-01, 2.4522e-01],\n",
      "        [6.5850e-01, 3.4150e-01],\n",
      "        [9.8408e-01, 1.5923e-02],\n",
      "        [5.4355e-01, 4.5645e-01],\n",
      "        [6.4259e-01, 3.5741e-01],\n",
      "        [7.4077e-01, 2.5923e-01],\n",
      "        [1.3219e-01, 8.6781e-01],\n",
      "        [6.1637e-01, 3.8363e-01],\n",
      "        [1.6004e-01, 8.3996e-01],\n",
      "        [6.2828e-01, 3.7172e-01],\n",
      "        [9.7078e-01, 2.9220e-02],\n",
      "        [7.1676e-01, 2.8324e-01],\n",
      "        [4.2067e-01, 5.7933e-01],\n",
      "        [5.0022e-01, 4.9978e-01],\n",
      "        [4.0287e-01, 5.9713e-01],\n",
      "        [5.9046e-01, 4.0954e-01],\n",
      "        [9.9933e-01, 6.6744e-04],\n",
      "        [5.3821e-01, 4.6179e-01],\n",
      "        [9.0850e-01, 9.1499e-02],\n",
      "        [3.7537e-01, 6.2463e-01],\n",
      "        [2.2693e-01, 7.7307e-01],\n",
      "        [2.5141e-01, 7.4859e-01],\n",
      "        [8.8795e-01, 1.1205e-01],\n",
      "        [1.3521e-02, 9.8648e-01],\n",
      "        [9.0535e-01, 9.4645e-02],\n",
      "        [9.7439e-01, 2.5609e-02],\n",
      "        [6.6949e-01, 3.3051e-01],\n",
      "        [7.0581e-01, 2.9419e-01],\n",
      "        [9.8609e-01, 1.3905e-02],\n",
      "        [5.2959e-01, 4.7041e-01],\n",
      "        [6.6539e-01, 3.3461e-01],\n",
      "        [8.0168e-01, 1.9832e-01],\n",
      "        [8.9701e-01, 1.0299e-01],\n",
      "        [3.1830e-01, 6.8170e-01],\n",
      "        [9.4845e-01, 5.1546e-02],\n",
      "        [9.2398e-01, 7.6018e-02],\n",
      "        [6.3314e-01, 3.6686e-01],\n",
      "        [5.7762e-01, 4.2238e-01],\n",
      "        [9.0553e-01, 9.4471e-02],\n",
      "        [5.6757e-01, 4.3243e-01],\n",
      "        [6.9293e-01, 3.0707e-01],\n",
      "        [6.5471e-01, 3.4529e-01],\n",
      "        [6.0528e-01, 3.9472e-01],\n",
      "        [7.3850e-01, 2.6150e-01],\n",
      "        [8.6320e-01, 1.3680e-01],\n",
      "        [7.3555e-01, 2.6445e-01],\n",
      "        [4.8201e-01, 5.1799e-01],\n",
      "        [7.4168e-01, 2.5832e-01],\n",
      "        [3.4445e-01, 6.5555e-01],\n",
      "        [5.9643e-01, 4.0357e-01],\n",
      "        [6.3890e-01, 3.6110e-01],\n",
      "        [5.0299e-01, 4.9701e-01],\n",
      "        [2.9634e-01, 7.0366e-01],\n",
      "        [6.6885e-01, 3.3115e-01],\n",
      "        [8.9097e-01, 1.0903e-01],\n",
      "        [2.8189e-01, 7.1811e-01],\n",
      "        [9.7133e-01, 2.8667e-02],\n",
      "        [2.2404e-01, 7.7596e-01],\n",
      "        [2.8283e-01, 7.1717e-01],\n",
      "        [3.9575e-01, 6.0425e-01],\n",
      "        [5.3446e-01, 4.6554e-01]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.8674, 0.8203, 0.9042, 0.7548, 0.6585, 0.9841, 0.5435, 0.6426, 0.7408,\n",
      "        0.8678, 0.6164, 0.8400, 0.6283, 0.9708, 0.7168, 0.5793, 0.5002, 0.5971,\n",
      "        0.5905, 0.9993, 0.5382, 0.9085, 0.6246, 0.7731, 0.7486, 0.8879, 0.9865,\n",
      "        0.9054, 0.9744, 0.6695, 0.7058, 0.9861, 0.5296, 0.6654, 0.8017, 0.8970,\n",
      "        0.6817, 0.9485, 0.9240, 0.6331, 0.5776, 0.9055, 0.5676, 0.6929, 0.6547,\n",
      "        0.6053, 0.7385, 0.8632, 0.7356, 0.5180, 0.7417, 0.6555, 0.5964, 0.6389,\n",
      "        0.5030, 0.7037, 0.6688, 0.8910, 0.7181, 0.9713, 0.7760, 0.7172, 0.6043,\n",
      "        0.5345], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.2714, 0.7286],\n",
      "        [0.8655, 0.1345],\n",
      "        [0.6094, 0.3906],\n",
      "        [0.8069, 0.1931],\n",
      "        [0.4066, 0.5934],\n",
      "        [0.6402, 0.3598],\n",
      "        [0.2143, 0.7857],\n",
      "        [0.9094, 0.0906],\n",
      "        [0.6453, 0.3547],\n",
      "        [0.9602, 0.0398],\n",
      "        [0.9052, 0.0948],\n",
      "        [0.4899, 0.5101],\n",
      "        [0.5976, 0.4024],\n",
      "        [0.8417, 0.1583],\n",
      "        [0.8822, 0.1178],\n",
      "        [0.8995, 0.1005],\n",
      "        [0.8548, 0.1452],\n",
      "        [0.4365, 0.5635],\n",
      "        [0.9521, 0.0479],\n",
      "        [0.4768, 0.5232],\n",
      "        [0.7926, 0.2074],\n",
      "        [0.1822, 0.8178],\n",
      "        [0.0796, 0.9204],\n",
      "        [0.0681, 0.9319],\n",
      "        [0.3326, 0.6674],\n",
      "        [0.4517, 0.5483],\n",
      "        [0.1837, 0.8163],\n",
      "        [0.8077, 0.1923],\n",
      "        [0.1561, 0.8439],\n",
      "        [0.3689, 0.6311],\n",
      "        [0.0896, 0.9104],\n",
      "        [0.5077, 0.4923],\n",
      "        [0.1013, 0.8987],\n",
      "        [0.1527, 0.8473],\n",
      "        [0.1584, 0.8416],\n",
      "        [0.0414, 0.9586],\n",
      "        [0.0202, 0.9798],\n",
      "        [0.0394, 0.9606]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7286, 0.8655, 0.6094, 0.8069, 0.5934, 0.6402, 0.7857, 0.9094, 0.6453,\n",
      "        0.9602, 0.9052, 0.5101, 0.5976, 0.8417, 0.8822, 0.8995, 0.8548, 0.5635,\n",
      "        0.9521, 0.5232, 0.7926, 0.8178, 0.9204, 0.9319, 0.6674, 0.5483, 0.8163,\n",
      "        0.8077, 0.8439, 0.6311, 0.9104, 0.5077, 0.8987, 0.8473, 0.8416, 0.9586,\n",
      "        0.9798, 0.9606], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 6, Training Loss: 0.43, Validation Loss: 0.53, accuracy = 0.75\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[8.7912e-01, 1.2088e-01],\n",
      "        [8.5778e-01, 1.4222e-01],\n",
      "        [9.3268e-01, 6.7320e-02],\n",
      "        [7.7727e-01, 2.2273e-01],\n",
      "        [6.8602e-01, 3.1398e-01],\n",
      "        [9.9156e-01, 8.4409e-03],\n",
      "        [5.5376e-01, 4.4624e-01],\n",
      "        [6.6346e-01, 3.3654e-01],\n",
      "        [7.6376e-01, 2.3624e-01],\n",
      "        [1.2548e-01, 8.7452e-01],\n",
      "        [6.0466e-01, 3.9534e-01],\n",
      "        [1.3748e-01, 8.6252e-01],\n",
      "        [6.7394e-01, 3.2606e-01],\n",
      "        [9.7992e-01, 2.0076e-02],\n",
      "        [7.7605e-01, 2.2395e-01],\n",
      "        [4.1079e-01, 5.8921e-01],\n",
      "        [4.9964e-01, 5.0036e-01],\n",
      "        [3.8581e-01, 6.1419e-01],\n",
      "        [6.2663e-01, 3.7337e-01],\n",
      "        [9.9974e-01, 2.6229e-04],\n",
      "        [5.4106e-01, 4.5894e-01],\n",
      "        [9.3877e-01, 6.1228e-02],\n",
      "        [3.7377e-01, 6.2623e-01],\n",
      "        [2.0164e-01, 7.9836e-01],\n",
      "        [2.0774e-01, 7.9226e-01],\n",
      "        [9.0004e-01, 9.9965e-02],\n",
      "        [1.0785e-02, 9.8922e-01],\n",
      "        [9.2522e-01, 7.4776e-02],\n",
      "        [9.8232e-01, 1.7679e-02],\n",
      "        [7.2574e-01, 2.7426e-01],\n",
      "        [7.4422e-01, 2.5578e-01],\n",
      "        [9.8957e-01, 1.0432e-02],\n",
      "        [6.1192e-01, 3.8808e-01],\n",
      "        [7.6193e-01, 2.3807e-01],\n",
      "        [8.3927e-01, 1.6073e-01],\n",
      "        [9.0968e-01, 9.0322e-02],\n",
      "        [2.9650e-01, 7.0350e-01],\n",
      "        [9.6705e-01, 3.2955e-02],\n",
      "        [9.5438e-01, 4.5622e-02],\n",
      "        [6.4162e-01, 3.5838e-01],\n",
      "        [6.2468e-01, 3.7532e-01],\n",
      "        [9.3308e-01, 6.6924e-02],\n",
      "        [6.0345e-01, 3.9655e-01],\n",
      "        [7.2900e-01, 2.7100e-01],\n",
      "        [6.4900e-01, 3.5100e-01],\n",
      "        [5.9838e-01, 4.0162e-01],\n",
      "        [7.4669e-01, 2.5331e-01],\n",
      "        [8.8532e-01, 1.1468e-01],\n",
      "        [7.7754e-01, 2.2246e-01],\n",
      "        [5.1742e-01, 4.8258e-01],\n",
      "        [7.4802e-01, 2.5198e-01],\n",
      "        [3.9879e-01, 6.0121e-01],\n",
      "        [6.1039e-01, 3.8961e-01],\n",
      "        [6.4370e-01, 3.5630e-01],\n",
      "        [5.3514e-01, 4.6486e-01],\n",
      "        [3.0778e-01, 6.9222e-01],\n",
      "        [6.6941e-01, 3.3059e-01],\n",
      "        [9.0273e-01, 9.7265e-02],\n",
      "        [3.4462e-01, 6.5538e-01],\n",
      "        [9.8160e-01, 1.8402e-02],\n",
      "        [2.2846e-01, 7.7154e-01],\n",
      "        [3.5028e-01, 6.4972e-01],\n",
      "        [4.2812e-01, 5.7188e-01],\n",
      "        [5.3377e-01, 4.6623e-01]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.8791, 0.8578, 0.9327, 0.7773, 0.6860, 0.9916, 0.5538, 0.6635, 0.7638,\n",
      "        0.8745, 0.6047, 0.8625, 0.6739, 0.9799, 0.7761, 0.5892, 0.5004, 0.6142,\n",
      "        0.6266, 0.9997, 0.5411, 0.9388, 0.6262, 0.7984, 0.7923, 0.9000, 0.9892,\n",
      "        0.9252, 0.9823, 0.7257, 0.7442, 0.9896, 0.6119, 0.7619, 0.8393, 0.9097,\n",
      "        0.7035, 0.9670, 0.9544, 0.6416, 0.6247, 0.9331, 0.6035, 0.7290, 0.6490,\n",
      "        0.5984, 0.7467, 0.8853, 0.7775, 0.5174, 0.7480, 0.6012, 0.6104, 0.6437,\n",
      "        0.5351, 0.6922, 0.6694, 0.9027, 0.6554, 0.9816, 0.7715, 0.6497, 0.5719,\n",
      "        0.5338], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False, False, False,  True,  True,\n",
      "         True,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.2828, 0.7172],\n",
      "        [0.9004, 0.0996],\n",
      "        [0.7236, 0.2764],\n",
      "        [0.8027, 0.1973],\n",
      "        [0.4161, 0.5839],\n",
      "        [0.6535, 0.3465],\n",
      "        [0.2153, 0.7847],\n",
      "        [0.9165, 0.0835],\n",
      "        [0.6595, 0.3405],\n",
      "        [0.9743, 0.0257],\n",
      "        [0.9293, 0.0707],\n",
      "        [0.5007, 0.4993],\n",
      "        [0.6281, 0.3719],\n",
      "        [0.8699, 0.1301],\n",
      "        [0.9055, 0.0945],\n",
      "        [0.9157, 0.0843],\n",
      "        [0.8793, 0.1207],\n",
      "        [0.4410, 0.5590],\n",
      "        [0.9685, 0.0315],\n",
      "        [0.4809, 0.5191],\n",
      "        [0.7884, 0.2116],\n",
      "        [0.1890, 0.8110],\n",
      "        [0.0639, 0.9361],\n",
      "        [0.0340, 0.9660],\n",
      "        [0.3636, 0.6364],\n",
      "        [0.5180, 0.4820],\n",
      "        [0.1765, 0.8235],\n",
      "        [0.8187, 0.1813],\n",
      "        [0.1642, 0.8358],\n",
      "        [0.3671, 0.6329],\n",
      "        [0.0738, 0.9262],\n",
      "        [0.5140, 0.4860],\n",
      "        [0.0906, 0.9094],\n",
      "        [0.1365, 0.8635],\n",
      "        [0.1373, 0.8627],\n",
      "        [0.0366, 0.9634],\n",
      "        [0.0155, 0.9845],\n",
      "        [0.0320, 0.9680]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7172, 0.9004, 0.7236, 0.8027, 0.5839, 0.6535, 0.7847, 0.9165, 0.6595,\n",
      "        0.9743, 0.9293, 0.5007, 0.6281, 0.8699, 0.9055, 0.9157, 0.8793, 0.5590,\n",
      "        0.9685, 0.5191, 0.7884, 0.8110, 0.9361, 0.9660, 0.6364, 0.5180, 0.8235,\n",
      "        0.8187, 0.8358, 0.6329, 0.9262, 0.5140, 0.9094, 0.8635, 0.8627, 0.9634,\n",
      "        0.9845, 0.9680], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 7, Training Loss: 0.40, Validation Loss: 0.51, accuracy = 0.75\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[8.8770e-01, 1.1230e-01],\n",
      "        [8.9356e-01, 1.0644e-01],\n",
      "        [9.4504e-01, 5.4956e-02],\n",
      "        [8.0019e-01, 1.9981e-01],\n",
      "        [7.0734e-01, 2.9266e-01],\n",
      "        [9.9417e-01, 5.8323e-03],\n",
      "        [5.4552e-01, 4.5448e-01],\n",
      "        [6.7513e-01, 3.2487e-01],\n",
      "        [7.9450e-01, 2.0550e-01],\n",
      "        [7.6340e-02, 9.2366e-01],\n",
      "        [6.2074e-01, 3.7926e-01],\n",
      "        [1.0954e-01, 8.9046e-01],\n",
      "        [6.9590e-01, 3.0410e-01],\n",
      "        [9.8450e-01, 1.5497e-02],\n",
      "        [7.7589e-01, 2.2411e-01],\n",
      "        [3.9309e-01, 6.0691e-01],\n",
      "        [5.1224e-01, 4.8776e-01],\n",
      "        [3.5329e-01, 6.4671e-01],\n",
      "        [6.5356e-01, 3.4644e-01],\n",
      "        [9.9987e-01, 1.2744e-04],\n",
      "        [4.9914e-01, 5.0086e-01],\n",
      "        [9.5465e-01, 4.5348e-02],\n",
      "        [2.9530e-01, 7.0470e-01],\n",
      "        [1.8044e-01, 8.1956e-01],\n",
      "        [1.6725e-01, 8.3275e-01],\n",
      "        [9.2589e-01, 7.4113e-02],\n",
      "        [7.2338e-03, 9.9277e-01],\n",
      "        [9.5076e-01, 4.9239e-02],\n",
      "        [9.8687e-01, 1.3133e-02],\n",
      "        [7.2587e-01, 2.7413e-01],\n",
      "        [7.7257e-01, 2.2743e-01],\n",
      "        [9.9403e-01, 5.9719e-03],\n",
      "        [5.8592e-01, 4.1408e-01],\n",
      "        [8.2787e-01, 1.7213e-01],\n",
      "        [8.7398e-01, 1.2602e-01],\n",
      "        [9.2137e-01, 7.8633e-02],\n",
      "        [2.7547e-01, 7.2453e-01],\n",
      "        [9.6706e-01, 3.2940e-02],\n",
      "        [9.7355e-01, 2.6454e-02],\n",
      "        [6.4074e-01, 3.5926e-01],\n",
      "        [5.9190e-01, 4.0810e-01],\n",
      "        [9.4442e-01, 5.5577e-02],\n",
      "        [5.6348e-01, 4.3652e-01],\n",
      "        [7.0385e-01, 2.9615e-01],\n",
      "        [6.2999e-01, 3.7001e-01],\n",
      "        [6.1564e-01, 3.8436e-01],\n",
      "        [7.6346e-01, 2.3654e-01],\n",
      "        [9.0854e-01, 9.1457e-02],\n",
      "        [8.0762e-01, 1.9238e-01],\n",
      "        [5.2251e-01, 4.7749e-01],\n",
      "        [7.5103e-01, 2.4897e-01],\n",
      "        [3.6501e-01, 6.3499e-01],\n",
      "        [6.1347e-01, 3.8653e-01],\n",
      "        [6.3666e-01, 3.6334e-01],\n",
      "        [5.2403e-01, 4.7597e-01],\n",
      "        [2.7318e-01, 7.2682e-01],\n",
      "        [6.5190e-01, 3.4810e-01],\n",
      "        [9.1739e-01, 8.2608e-02],\n",
      "        [3.2592e-01, 6.7408e-01],\n",
      "        [9.8997e-01, 1.0033e-02],\n",
      "        [2.1708e-01, 7.8292e-01],\n",
      "        [2.4274e-01, 7.5726e-01],\n",
      "        [3.6094e-01, 6.3906e-01],\n",
      "        [5.1527e-01, 4.8473e-01]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.8877, 0.8936, 0.9450, 0.8002, 0.7073, 0.9942, 0.5455, 0.6751, 0.7945,\n",
      "        0.9237, 0.6207, 0.8905, 0.6959, 0.9845, 0.7759, 0.6069, 0.5122, 0.6467,\n",
      "        0.6536, 0.9999, 0.5009, 0.9547, 0.7047, 0.8196, 0.8328, 0.9259, 0.9928,\n",
      "        0.9508, 0.9869, 0.7259, 0.7726, 0.9940, 0.5859, 0.8279, 0.8740, 0.9214,\n",
      "        0.7245, 0.9671, 0.9735, 0.6407, 0.5919, 0.9444, 0.5635, 0.7038, 0.6300,\n",
      "        0.6156, 0.7635, 0.9085, 0.8076, 0.5225, 0.7510, 0.6350, 0.6135, 0.6367,\n",
      "        0.5240, 0.7268, 0.6519, 0.9174, 0.6741, 0.9900, 0.7829, 0.7573, 0.6391,\n",
      "        0.5153], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "        False,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.2563, 0.7437],\n",
      "        [0.8942, 0.1058],\n",
      "        [0.7054, 0.2946],\n",
      "        [0.8065, 0.1935],\n",
      "        [0.4179, 0.5821],\n",
      "        [0.6839, 0.3161],\n",
      "        [0.2060, 0.7940],\n",
      "        [0.9278, 0.0722],\n",
      "        [0.6651, 0.3349],\n",
      "        [0.9826, 0.0174],\n",
      "        [0.9532, 0.0468],\n",
      "        [0.5061, 0.4939],\n",
      "        [0.6362, 0.3638],\n",
      "        [0.8901, 0.1099],\n",
      "        [0.9227, 0.0773],\n",
      "        [0.9311, 0.0689],\n",
      "        [0.9059, 0.0941],\n",
      "        [0.4454, 0.5546],\n",
      "        [0.9782, 0.0218],\n",
      "        [0.4007, 0.5993],\n",
      "        [0.8083, 0.1917],\n",
      "        [0.1514, 0.8486],\n",
      "        [0.0478, 0.9522],\n",
      "        [0.0157, 0.9843],\n",
      "        [0.2447, 0.7553],\n",
      "        [0.5112, 0.4888],\n",
      "        [0.1436, 0.8564],\n",
      "        [0.8323, 0.1677],\n",
      "        [0.1358, 0.8642],\n",
      "        [0.3474, 0.6526],\n",
      "        [0.0516, 0.9484],\n",
      "        [0.5133, 0.4867],\n",
      "        [0.0566, 0.9434],\n",
      "        [0.1120, 0.8880],\n",
      "        [0.0860, 0.9140],\n",
      "        [0.0284, 0.9716],\n",
      "        [0.0096, 0.9904],\n",
      "        [0.0219, 0.9781]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7437, 0.8942, 0.7054, 0.8065, 0.5821, 0.6839, 0.7940, 0.9278, 0.6651,\n",
      "        0.9826, 0.9532, 0.5061, 0.6362, 0.8901, 0.9227, 0.9311, 0.9059, 0.5546,\n",
      "        0.9782, 0.5993, 0.8083, 0.8486, 0.9522, 0.9843, 0.7553, 0.5112, 0.8564,\n",
      "        0.8323, 0.8642, 0.6526, 0.9484, 0.5133, 0.9434, 0.8880, 0.9140, 0.9716,\n",
      "        0.9904, 0.9781], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 8, Training Loss: 0.36, Validation Loss: 0.53, accuracy = 0.75\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[8.9613e-01, 1.0387e-01],\n",
      "        [9.1784e-01, 8.2161e-02],\n",
      "        [9.5955e-01, 4.0453e-02],\n",
      "        [8.1811e-01, 1.8189e-01],\n",
      "        [7.3391e-01, 2.6609e-01],\n",
      "        [9.9666e-01, 3.3369e-03],\n",
      "        [5.5740e-01, 4.4260e-01],\n",
      "        [6.9656e-01, 3.0344e-01],\n",
      "        [8.1666e-01, 1.8334e-01],\n",
      "        [7.2179e-02, 9.2782e-01],\n",
      "        [6.0113e-01, 3.9887e-01],\n",
      "        [9.1834e-02, 9.0817e-01],\n",
      "        [7.5347e-01, 2.4653e-01],\n",
      "        [9.8858e-01, 1.1424e-02],\n",
      "        [8.2720e-01, 1.7280e-01],\n",
      "        [3.6202e-01, 6.3798e-01],\n",
      "        [4.9172e-01, 5.0828e-01],\n",
      "        [3.1060e-01, 6.8940e-01],\n",
      "        [6.7519e-01, 3.2481e-01],\n",
      "        [9.9994e-01, 5.7701e-05],\n",
      "        [4.8884e-01, 5.1116e-01],\n",
      "        [9.6973e-01, 3.0267e-02],\n",
      "        [2.7823e-01, 7.2177e-01],\n",
      "        [1.7591e-01, 8.2409e-01],\n",
      "        [1.3643e-01, 8.6357e-01],\n",
      "        [9.2882e-01, 7.1184e-02],\n",
      "        [7.1161e-03, 9.9288e-01],\n",
      "        [9.6039e-01, 3.9614e-02],\n",
      "        [9.8988e-01, 1.0124e-02],\n",
      "        [7.8812e-01, 2.1188e-01],\n",
      "        [8.1286e-01, 1.8714e-01],\n",
      "        [9.9550e-01, 4.4990e-03],\n",
      "        [7.2834e-01, 2.7166e-01],\n",
      "        [8.8824e-01, 1.1176e-01],\n",
      "        [8.9145e-01, 1.0855e-01],\n",
      "        [9.2717e-01, 7.2827e-02],\n",
      "        [2.6608e-01, 7.3392e-01],\n",
      "        [9.7868e-01, 2.1317e-02],\n",
      "        [9.8392e-01, 1.6085e-02],\n",
      "        [6.5605e-01, 3.4395e-01],\n",
      "        [6.7389e-01, 3.2611e-01],\n",
      "        [9.6039e-01, 3.9609e-02],\n",
      "        [6.0642e-01, 3.9358e-01],\n",
      "        [7.3302e-01, 2.6698e-01],\n",
      "        [6.2649e-01, 3.7351e-01],\n",
      "        [5.8875e-01, 4.1125e-01],\n",
      "        [7.7249e-01, 2.2751e-01],\n",
      "        [9.2513e-01, 7.4868e-02],\n",
      "        [8.3644e-01, 1.6356e-01],\n",
      "        [5.7917e-01, 4.2083e-01],\n",
      "        [7.6584e-01, 2.3416e-01],\n",
      "        [4.2890e-01, 5.7110e-01],\n",
      "        [6.2652e-01, 3.7348e-01],\n",
      "        [6.4267e-01, 3.5733e-01],\n",
      "        [5.6770e-01, 4.3230e-01],\n",
      "        [3.0020e-01, 6.9980e-01],\n",
      "        [6.5817e-01, 3.4183e-01],\n",
      "        [9.2381e-01, 7.6187e-02],\n",
      "        [4.3783e-01, 5.6217e-01],\n",
      "        [9.9309e-01, 6.9095e-03],\n",
      "        [2.3640e-01, 7.6360e-01],\n",
      "        [3.2974e-01, 6.7026e-01],\n",
      "        [3.9915e-01, 6.0085e-01],\n",
      "        [5.0881e-01, 4.9119e-01]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.8961, 0.9178, 0.9595, 0.8181, 0.7339, 0.9967, 0.5574, 0.6966, 0.8167,\n",
      "        0.9278, 0.6011, 0.9082, 0.7535, 0.9886, 0.8272, 0.6380, 0.5083, 0.6894,\n",
      "        0.6752, 0.9999, 0.5112, 0.9697, 0.7218, 0.8241, 0.8636, 0.9288, 0.9929,\n",
      "        0.9604, 0.9899, 0.7881, 0.8129, 0.9955, 0.7283, 0.8882, 0.8915, 0.9272,\n",
      "        0.7339, 0.9787, 0.9839, 0.6561, 0.6739, 0.9604, 0.6064, 0.7330, 0.6265,\n",
      "        0.5887, 0.7725, 0.9251, 0.8364, 0.5792, 0.7658, 0.5711, 0.6265, 0.6427,\n",
      "        0.5677, 0.6998, 0.6582, 0.9238, 0.5622, 0.9931, 0.7636, 0.6703, 0.6008,\n",
      "        0.5088], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False, False, False,  True,  True,\n",
      "        False,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False,  True], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.2647, 0.7353],\n",
      "        [0.9171, 0.0829],\n",
      "        [0.8004, 0.1996],\n",
      "        [0.8071, 0.1929],\n",
      "        [0.4611, 0.5389],\n",
      "        [0.7223, 0.2777],\n",
      "        [0.2233, 0.7767],\n",
      "        [0.9323, 0.0677],\n",
      "        [0.6818, 0.3182],\n",
      "        [0.9876, 0.0124],\n",
      "        [0.9608, 0.0392],\n",
      "        [0.5220, 0.4780],\n",
      "        [0.6668, 0.3332],\n",
      "        [0.9105, 0.0895],\n",
      "        [0.9394, 0.0606],\n",
      "        [0.9389, 0.0611],\n",
      "        [0.9240, 0.0760],\n",
      "        [0.4984, 0.5016],\n",
      "        [0.9846, 0.0154],\n",
      "        [0.4291, 0.5709],\n",
      "        [0.7722, 0.2278],\n",
      "        [0.1861, 0.8139],\n",
      "        [0.0441, 0.9559],\n",
      "        [0.0083, 0.9917],\n",
      "        [0.2972, 0.7028],\n",
      "        [0.5826, 0.4174],\n",
      "        [0.1656, 0.8344],\n",
      "        [0.8368, 0.1632],\n",
      "        [0.1539, 0.8461],\n",
      "        [0.3683, 0.6317],\n",
      "        [0.0456, 0.9544],\n",
      "        [0.5336, 0.4664],\n",
      "        [0.0633, 0.9367],\n",
      "        [0.1024, 0.8976],\n",
      "        [0.0630, 0.9370],\n",
      "        [0.0278, 0.9722],\n",
      "        [0.0091, 0.9909],\n",
      "        [0.0190, 0.9810]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7353, 0.9171, 0.8004, 0.8071, 0.5389, 0.7223, 0.7767, 0.9323, 0.6818,\n",
      "        0.9876, 0.9608, 0.5220, 0.6668, 0.9105, 0.9394, 0.9389, 0.9240, 0.5016,\n",
      "        0.9846, 0.5709, 0.7722, 0.8139, 0.9559, 0.9917, 0.7028, 0.5826, 0.8344,\n",
      "        0.8368, 0.8461, 0.6317, 0.9544, 0.5336, 0.9367, 0.8976, 0.9370, 0.9722,\n",
      "        0.9909, 0.9810], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 9, Training Loss: 0.33, Validation Loss: 0.51, accuracy = 0.75\n",
      "Output Shape: torch.Size([64, 2])\n",
      "F.softmax(output, dim=1): tensor([[9.0173e-01, 9.8271e-02],\n",
      "        [9.3820e-01, 6.1804e-02],\n",
      "        [9.6952e-01, 3.0481e-02],\n",
      "        [8.3183e-01, 1.6817e-01],\n",
      "        [7.6032e-01, 2.3968e-01],\n",
      "        [9.9761e-01, 2.3867e-03],\n",
      "        [5.5538e-01, 4.4462e-01],\n",
      "        [7.1546e-01, 2.8454e-01],\n",
      "        [8.5504e-01, 1.4496e-01],\n",
      "        [4.7019e-02, 9.5298e-01],\n",
      "        [6.3415e-01, 3.6585e-01],\n",
      "        [6.8043e-02, 9.3196e-01],\n",
      "        [7.6830e-01, 2.3170e-01],\n",
      "        [9.9072e-01, 9.2768e-03],\n",
      "        [8.1154e-01, 1.8846e-01],\n",
      "        [3.3086e-01, 6.6914e-01],\n",
      "        [5.3844e-01, 4.6156e-01],\n",
      "        [2.9641e-01, 7.0359e-01],\n",
      "        [7.1463e-01, 2.8537e-01],\n",
      "        [9.9997e-01, 2.7650e-05],\n",
      "        [4.6971e-01, 5.3029e-01],\n",
      "        [9.7828e-01, 2.1722e-02],\n",
      "        [2.2756e-01, 7.7244e-01],\n",
      "        [1.4647e-01, 8.5353e-01],\n",
      "        [1.0855e-01, 8.9145e-01],\n",
      "        [9.5046e-01, 4.9539e-02],\n",
      "        [4.5537e-03, 9.9545e-01],\n",
      "        [9.7485e-01, 2.5154e-02],\n",
      "        [9.9211e-01, 7.8859e-03],\n",
      "        [7.8882e-01, 2.1118e-01],\n",
      "        [8.2576e-01, 1.7424e-01],\n",
      "        [9.9709e-01, 2.9079e-03],\n",
      "        [6.8013e-01, 3.1987e-01],\n",
      "        [8.9500e-01, 1.0500e-01],\n",
      "        [9.1323e-01, 8.6767e-02],\n",
      "        [9.3497e-01, 6.5025e-02],\n",
      "        [2.3176e-01, 7.6824e-01],\n",
      "        [9.7734e-01, 2.2665e-02],\n",
      "        [9.9107e-01, 8.9332e-03],\n",
      "        [6.5471e-01, 3.4529e-01],\n",
      "        [5.7589e-01, 4.2411e-01],\n",
      "        [9.6765e-01, 3.2355e-02],\n",
      "        [5.7316e-01, 4.2684e-01],\n",
      "        [7.1479e-01, 2.8521e-01],\n",
      "        [6.2550e-01, 3.7450e-01],\n",
      "        [5.9203e-01, 4.0797e-01],\n",
      "        [7.8474e-01, 2.1526e-01],\n",
      "        [9.4105e-01, 5.8954e-02],\n",
      "        [8.5060e-01, 1.4940e-01],\n",
      "        [5.6344e-01, 4.3656e-01],\n",
      "        [7.6834e-01, 2.3166e-01],\n",
      "        [4.1337e-01, 5.8663e-01],\n",
      "        [6.3155e-01, 3.6845e-01],\n",
      "        [6.4786e-01, 3.5214e-01],\n",
      "        [5.6164e-01, 4.3836e-01],\n",
      "        [3.0069e-01, 6.9931e-01],\n",
      "        [6.5877e-01, 3.4123e-01],\n",
      "        [9.3121e-01, 6.8786e-02],\n",
      "        [4.2245e-01, 5.7755e-01],\n",
      "        [9.9585e-01, 4.1461e-03],\n",
      "        [2.2995e-01, 7.7005e-01],\n",
      "        [1.5571e-01, 8.4429e-01],\n",
      "        [3.3485e-01, 6.6515e-01],\n",
      "        [4.9979e-01, 5.0021e-01]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.9017, 0.9382, 0.9695, 0.8318, 0.7603, 0.9976, 0.5554, 0.7155, 0.8550,\n",
      "        0.9530, 0.6342, 0.9320, 0.7683, 0.9907, 0.8115, 0.6691, 0.5384, 0.7036,\n",
      "        0.7146, 1.0000, 0.5303, 0.9783, 0.7724, 0.8535, 0.8914, 0.9505, 0.9954,\n",
      "        0.9748, 0.9921, 0.7888, 0.8258, 0.9971, 0.6801, 0.8950, 0.9132, 0.9350,\n",
      "        0.7682, 0.9773, 0.9911, 0.6547, 0.5759, 0.9676, 0.5732, 0.7148, 0.6255,\n",
      "        0.5920, 0.7847, 0.9410, 0.8506, 0.5634, 0.7683, 0.5866, 0.6315, 0.6479,\n",
      "        0.5616, 0.6993, 0.6588, 0.9312, 0.5776, 0.9959, 0.7701, 0.8443, 0.6652,\n",
      "        0.5002], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "        False,  True, False, False, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True, False,  True,  True,  True, False,  True,  True, False,  True,\n",
      "        False, False, False, False], device='mps:0')\n",
      "Output Shape: torch.Size([38, 2])\n",
      "F.softmax(output, dim=1): tensor([[0.2339, 0.7661],\n",
      "        [0.9073, 0.0927],\n",
      "        [0.7723, 0.2277],\n",
      "        [0.8075, 0.1925],\n",
      "        [0.4135, 0.5865],\n",
      "        [0.7557, 0.2443],\n",
      "        [0.2079, 0.7921],\n",
      "        [0.9385, 0.0615],\n",
      "        [0.6925, 0.3075],\n",
      "        [0.9912, 0.0088],\n",
      "        [0.9714, 0.0286],\n",
      "        [0.5321, 0.4679],\n",
      "        [0.6779, 0.3221],\n",
      "        [0.9235, 0.0765],\n",
      "        [0.9484, 0.0516],\n",
      "        [0.9513, 0.0487],\n",
      "        [0.9429, 0.0571],\n",
      "        [0.4388, 0.5612],\n",
      "        [0.9891, 0.0109],\n",
      "        [0.3460, 0.6540],\n",
      "        [0.7688, 0.2312],\n",
      "        [0.1390, 0.8610],\n",
      "        [0.0354, 0.9646],\n",
      "        [0.0033, 0.9967],\n",
      "        [0.1980, 0.8020],\n",
      "        [0.5880, 0.4120],\n",
      "        [0.1195, 0.8805],\n",
      "        [0.8406, 0.1594],\n",
      "        [0.1380, 0.8620],\n",
      "        [0.3019, 0.6981],\n",
      "        [0.0283, 0.9717],\n",
      "        [0.5359, 0.4641],\n",
      "        [0.0357, 0.9643],\n",
      "        [0.0814, 0.9186],\n",
      "        [0.0438, 0.9562],\n",
      "        [0.0211, 0.9789],\n",
      "        [0.0052, 0.9948],\n",
      "        [0.0128, 0.9872]], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.max(F.softmax(output, dim=1), dim=1): torch.return_types.max(\n",
      "values=tensor([0.7661, 0.9073, 0.7723, 0.8075, 0.5865, 0.7557, 0.7921, 0.9385, 0.6925,\n",
      "        0.9912, 0.9714, 0.5321, 0.6779, 0.9235, 0.9484, 0.9513, 0.9429, 0.5612,\n",
      "        0.9891, 0.6540, 0.7688, 0.8610, 0.9646, 0.9967, 0.8020, 0.5880, 0.8805,\n",
      "        0.8406, 0.8620, 0.6981, 0.9717, 0.5359, 0.9643, 0.9186, 0.9562, 0.9789,\n",
      "        0.9948, 0.9872], device='mps:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0'))\n",
      "torch.max(F.softmax(output, dim=1), dim=1)[1]: tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "targetstensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='mps:0')\n",
      "torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets):tensor([False,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
      "         True, False,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         True, False,  True,  True,  True,  True,  True,  True],\n",
      "       device='mps:0')\n",
      "Epoch: 10, Training Loss: 0.29, Validation Loss: 0.55, accuracy = 0.75\n",
      "CPU times: user 18.2 s, sys: 1.25 s, total: 19.5 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%time train(simplenet, optimizer,torch.nn.CrossEntropyLoss(), train_data_loader,val_data_loader, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "Labels are in alphanumeric order, so `cat` will be 0, `fish` will be 1. We'll need to transform the image and also make sure that the resulting tensor is copied to the appropriate device before applying our model to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T15:04:07.536489Z",
     "start_time": "2023-10-23T15:04:06.707069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n"
     ]
    }
   ],
   "source": [
    "labels = ['cat','fish']\n",
    "\n",
    "img = Image.open(\"../data/val/fish/100_1422.JPG\") \n",
    "img = img_transforms(img).to(device)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "\n",
    "simplenet.eval()\n",
    "prediction = F.softmax(simplenet(img), dim=1)\n",
    "prediction = prediction.argmax()\n",
    "print(labels[prediction]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "\n",
    "We can either save the entire model using `save` or just the parameters using `state_dict`. Using the latter is normally preferable, as it allows you to reuse parameters even if the model's structure changes (or apply parameters from one model to another)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T15:04:15.907364Z",
     "start_time": "2023-10-23T15:04:15.830070Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(simplenet, \"tmp/simplenet\") \n",
    "simplenet = torch.load(\"tmp/simplenet\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T15:04:16.903376Z",
     "start_time": "2023-10-23T15:04:16.838765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(simplenet.state_dict(), \"tmp/simplenet\")    \n",
    "simplenet = SimpleNet()\n",
    "simplenet_state_dict = torch.load(\"tmp/simplenet\")\n",
    "simplenet.load_state_dict(simplenet_state_dict, strict=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('fc1.weight',\n              tensor([[-7.6798e-03, -9.6895e-04,  9.2678e-03,  ...,  8.6839e-03,\n                        7.6343e-03, -6.1496e-04],\n                      [ 4.8398e-03,  6.5706e-03,  3.9849e-03,  ...,  3.6685e-03,\n                        5.5833e-03,  8.1738e-03],\n                      [-2.6032e-03,  4.9011e-03,  7.9491e-03,  ..., -5.2361e-03,\n                        3.9874e-03, -4.5173e-03],\n                      ...,\n                      [ 2.8446e-03, -7.0135e-03,  4.9849e-03,  ...,  2.8595e-03,\n                       -2.8795e-03, -9.3262e-03],\n                      [-6.5447e-03,  2.4438e-03, -8.7639e-03,  ...,  2.7842e-05,\n                       -1.3247e-03, -6.4040e-04],\n                      [ 4.3212e-03,  2.5143e-03, -2.4288e-03,  ...,  4.0716e-03,\n                        5.8293e-03, -4.0808e-04]])),\n             ('fc1.bias',\n              tensor([0.0022, 0.0028, 0.0052,  ..., 0.0008, 0.0076, 0.0013])),\n             ('fc2.weight',\n              tensor([[ 0.0270,  0.0111,  0.0145,  ...,  0.0113, -0.0030, -0.0029],\n                      [ 0.0143,  0.0271, -0.0109,  ...,  0.0199,  0.0083,  0.0043],\n                      [-0.0125,  0.0187, -0.0154,  ..., -0.0078, -0.0088,  0.0201],\n                      ...,\n                      [ 0.0022,  0.0250, -0.0081,  ..., -0.0335,  0.0069,  0.0306],\n                      [ 0.0058, -0.0155, -0.0263,  ...,  0.0290, -0.0107, -0.0049],\n                      [-0.0121, -0.0309,  0.0015,  ..., -0.0188,  0.0154,  0.0202]])),\n             ('fc2.bias',\n              tensor([ 2.5568e-02, -1.6097e-02, -5.4224e-03, -1.2452e-02,  2.0207e-02,\n                       2.7462e-02,  2.9392e-02, -1.7076e-02, -2.5437e-02, -1.3168e-02,\n                       1.4075e-02, -2.5236e-02,  5.7136e-03, -8.7687e-03, -1.4761e-02,\n                       1.7307e-02,  1.9407e-02,  1.1876e-04,  2.2412e-02,  8.5870e-03,\n                       2.5395e-02, -6.3540e-03,  3.0344e-02,  1.1737e-02,  1.5878e-02,\n                       2.6573e-02, -7.2126e-03,  4.4815e-03,  1.4899e-02,  7.8958e-04,\n                      -3.0380e-02,  2.0924e-02,  1.7263e-02, -8.3868e-03, -1.4775e-02,\n                       3.3923e-03,  1.9599e-02,  5.7724e-03, -1.7975e-02,  2.4383e-02,\n                      -2.2585e-02,  1.6711e-02, -6.1250e-03, -1.6370e-02,  1.1525e-02,\n                      -1.6363e-02, -2.6364e-02,  6.2273e-03,  1.6756e-02, -2.8819e-02,\n                      -1.2166e-02,  2.3290e-02,  1.7351e-02, -2.2834e-02,  7.7446e-03,\n                      -2.3486e-02,  2.5648e-02, -1.3238e-02,  2.0338e-02, -2.6784e-02,\n                       3.1190e-03,  4.8298e-03, -6.6125e-03, -2.2275e-02, -1.1244e-03,\n                      -1.0917e-02,  2.7225e-02, -1.7577e-02, -5.1391e-04,  1.4088e-02,\n                      -1.5250e-02,  7.0204e-03, -3.1617e-02, -1.5360e-02, -1.3332e-02,\n                       2.7206e-02, -9.4565e-04,  1.7178e-02,  2.8384e-02,  9.7815e-03,\n                       1.6335e-02,  2.0365e-02,  1.1561e-03, -7.5535e-05,  2.4328e-02,\n                      -6.0109e-03, -1.6935e-03,  2.0908e-02, -1.7790e-02,  3.0274e-02,\n                      -1.2767e-02,  6.1738e-03,  1.0213e-02,  3.3344e-03, -9.4190e-03,\n                      -2.1254e-02,  1.7322e-02,  1.3178e-02,  1.7416e-02,  2.5003e-02,\n                      -1.1009e-02, -1.3145e-02,  1.9957e-02, -1.6708e-02,  5.3203e-03,\n                      -1.2756e-02, -2.8807e-02, -1.0734e-02,  1.5233e-02,  1.8845e-02,\n                      -1.2022e-02, -6.0299e-03,  2.7156e-03,  1.8910e-02,  2.8038e-02,\n                       1.0113e-03, -2.4544e-02,  7.9683e-03, -1.9574e-02,  3.0258e-03,\n                      -3.3372e-03, -1.1867e-02,  1.5909e-02, -6.0829e-03,  2.6333e-03,\n                      -2.1977e-02,  2.6475e-03, -2.8028e-02, -1.0281e-02, -3.7994e-03,\n                      -5.5058e-04,  2.6426e-02,  3.1459e-02,  2.4483e-02, -1.9380e-02,\n                      -1.1207e-02, -2.9180e-02,  4.4024e-03,  1.6973e-02, -2.8245e-02,\n                       1.5583e-02, -1.2297e-02,  2.8305e-03, -1.1131e-02, -2.5392e-02,\n                       2.2144e-02, -1.8605e-02, -1.6226e-02,  2.6037e-02,  1.5234e-03,\n                      -2.3988e-02, -1.0389e-02,  2.3586e-03,  6.5057e-03,  3.1310e-02,\n                      -4.1222e-04, -1.9751e-02, -1.4044e-02,  2.0974e-03,  1.3760e-02,\n                       3.2034e-02,  8.1892e-03, -2.1192e-02, -3.9809e-03,  3.1077e-02,\n                      -1.0874e-02, -1.4905e-02, -2.7310e-02,  2.6227e-02, -2.6565e-02,\n                       1.0608e-02,  4.4767e-03, -1.8904e-02,  3.0166e-02,  1.1335e-02,\n                      -2.5559e-02, -4.7166e-05,  2.8867e-02, -8.9771e-03, -2.0985e-02,\n                       2.5386e-02, -1.7924e-02, -3.8869e-03, -1.0614e-02, -6.2203e-03,\n                       2.9928e-02, -2.6611e-02,  2.4393e-02,  1.6543e-02, -1.1867e-02,\n                      -1.2475e-03,  1.0561e-02, -7.2873e-03,  1.2136e-02,  2.8146e-02,\n                       2.5004e-02,  2.4694e-03, -1.2137e-02, -2.7327e-02,  4.5019e-03,\n                      -1.4617e-03, -1.9207e-02, -1.2258e-02, -2.3840e-02,  3.6521e-03,\n                      -1.6200e-02, -1.0994e-02,  1.9264e-02,  1.6097e-02,  2.8776e-02,\n                      -2.9516e-02, -2.4496e-02, -7.5260e-03,  1.5448e-02,  2.6264e-02,\n                       6.9228e-03,  2.7325e-03, -2.8211e-02,  2.6474e-02,  3.8296e-03,\n                      -1.6773e-02,  1.7738e-02,  5.3100e-03, -1.0246e-02,  3.0056e-02,\n                      -2.3977e-02,  2.1132e-02, -1.2546e-02,  2.5150e-02,  2.5495e-02,\n                      -1.6010e-02, -3.5280e-03, -1.1060e-02,  3.2290e-02, -1.5854e-02,\n                       2.8401e-02, -2.1597e-02,  5.2616e-03,  7.3649e-03, -1.6004e-02,\n                       3.0100e-02, -2.9634e-02,  2.7306e-02,  5.7541e-03,  2.7239e-02,\n                      -1.8686e-02,  7.3177e-03,  1.8548e-02,  1.5308e-02, -2.9212e-02,\n                      -6.1420e-03, -2.6025e-02, -2.8175e-02, -8.9476e-03, -2.9870e-02,\n                      -1.6295e-02])),\n             ('fc3.weight',\n              tensor([[ 0.0045, -0.0351, -0.0539,  ..., -0.0515, -0.0129, -0.0406],\n                      [ 0.0145,  0.0128,  0.0280,  ...,  0.0557, -0.0364,  0.0445],\n                      [-0.0115,  0.0594, -0.0121,  ...,  0.0575,  0.0103, -0.0173],\n                      ...,\n                      [ 0.0291,  0.0343, -0.0183,  ..., -0.0132, -0.0380,  0.0136],\n                      [-0.0346,  0.0386, -0.0402,  ..., -0.0351, -0.0179,  0.0606],\n                      [ 0.0001, -0.0241, -0.0161,  ..., -0.0594,  0.0034, -0.0440]])),\n             ('fc3.bias',\n              tensor([-2.6109e-02, -5.7945e-03, -3.9762e-02,  4.3952e-02, -1.7938e-02,\n                       3.4628e-02,  7.4899e-04,  2.6268e-02, -3.7313e-02, -2.1621e-02,\n                      -5.5444e-02,  5.6663e-02, -3.9074e-02, -8.7593e-03, -4.9810e-02,\n                       3.1303e-02,  1.7150e-02, -5.7072e-02, -3.7479e-02,  3.7166e-02,\n                       5.0821e-02,  5.2864e-02,  3.9231e-02,  4.4318e-02,  4.1923e-02,\n                       5.0394e-02,  3.1626e-03,  3.2102e-02, -1.7746e-02, -1.2731e-02,\n                      -2.9757e-02,  3.9205e-03, -1.2134e-02, -1.0880e-02,  6.2868e-02,\n                      -3.0065e-02, -4.1219e-02,  3.1251e-02, -1.1670e-02,  2.5520e-02,\n                       1.6216e-03, -4.7154e-02,  4.0414e-02,  4.1178e-02, -5.5621e-02,\n                       1.9618e-02,  2.8360e-02,  3.7518e-02, -3.1979e-02,  2.7978e-02,\n                      -1.9470e-02, -1.6481e-05, -2.5828e-02,  1.7133e-02, -3.2478e-03,\n                       1.8198e-02, -4.6413e-02,  3.0359e-03,  5.8683e-02,  1.2545e-02,\n                      -3.2370e-02, -5.3516e-02, -6.1211e-02, -8.4810e-03])),\n             ('fc4.weight',\n              tensor([[ 0.0810, -0.0601,  0.0253,  0.0081, -0.0036,  0.0669, -0.0492, -0.1147,\n                       -0.0913,  0.0689, -0.0011,  0.0247, -0.0100, -0.0529, -0.1235,  0.0162,\n                       -0.0173, -0.1185, -0.0729,  0.0982, -0.0856,  0.0093, -0.1132, -0.0415,\n                        0.0016, -0.0783,  0.1236, -0.0619,  0.0092,  0.1039,  0.0366, -0.0739,\n                       -0.1061,  0.0713,  0.0532, -0.0695, -0.0763, -0.0677,  0.0608, -0.0211,\n                        0.0873,  0.0450, -0.0603, -0.1232, -0.0980, -0.1070,  0.0807,  0.0104,\n                        0.1246,  0.0211,  0.0801,  0.0610,  0.0079, -0.1175,  0.0439, -0.0747,\n                        0.1183, -0.0734,  0.0658, -0.0879,  0.0325,  0.0852, -0.0146, -0.0788],\n                      [ 0.0540, -0.0116,  0.0364, -0.0581, -0.0374,  0.0481, -0.0450, -0.0203,\n                       -0.0503, -0.1025,  0.0396, -0.0519, -0.1194,  0.0017, -0.0264, -0.0758,\n                       -0.0906, -0.0627,  0.0277,  0.1133, -0.0804, -0.0574, -0.0532, -0.0043,\n                       -0.0849, -0.0598,  0.0261,  0.0693, -0.0168, -0.1014,  0.0473,  0.0112,\n                       -0.0461,  0.0074,  0.0135,  0.0622, -0.0878, -0.1126,  0.0175,  0.0021,\n                       -0.0180,  0.0815, -0.0011, -0.1141, -0.0133, -0.0794, -0.1039, -0.0627,\n                       -0.0789,  0.0334,  0.0578,  0.1007, -0.0890,  0.0964,  0.0297,  0.0122,\n                       -0.0771,  0.0575,  0.0225,  0.0230,  0.1016, -0.0350,  0.1064,  0.0518]])),\n             ('fc4.bias', tensor([-0.0794,  0.0450]))])"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplenet.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T15:04:17.774854Z",
     "start_time": "2023-10-23T15:04:17.760597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/main\" to /Users/saadnaeem/.cache/torch/hub/main.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": "['alexnet',\n 'convnext_base',\n 'convnext_large',\n 'convnext_small',\n 'convnext_tiny',\n 'deeplabv3_mobilenet_v3_large',\n 'deeplabv3_resnet101',\n 'deeplabv3_resnet50',\n 'densenet121',\n 'densenet161',\n 'densenet169',\n 'densenet201',\n 'efficientnet_b0',\n 'efficientnet_b1',\n 'efficientnet_b2',\n 'efficientnet_b3',\n 'efficientnet_b4',\n 'efficientnet_b5',\n 'efficientnet_b6',\n 'efficientnet_b7',\n 'efficientnet_v2_l',\n 'efficientnet_v2_m',\n 'efficientnet_v2_s',\n 'fcn_resnet101',\n 'fcn_resnet50',\n 'get_model_weights',\n 'get_weight',\n 'googlenet',\n 'inception_v3',\n 'lraspp_mobilenet_v3_large',\n 'maxvit_t',\n 'mc3_18',\n 'mnasnet0_5',\n 'mnasnet0_75',\n 'mnasnet1_0',\n 'mnasnet1_3',\n 'mobilenet_v2',\n 'mobilenet_v3_large',\n 'mobilenet_v3_small',\n 'mvit_v1_b',\n 'mvit_v2_s',\n 'r2plus1d_18',\n 'r3d_18',\n 'raft_large',\n 'raft_small',\n 'regnet_x_16gf',\n 'regnet_x_1_6gf',\n 'regnet_x_32gf',\n 'regnet_x_3_2gf',\n 'regnet_x_400mf',\n 'regnet_x_800mf',\n 'regnet_x_8gf',\n 'regnet_y_128gf',\n 'regnet_y_16gf',\n 'regnet_y_1_6gf',\n 'regnet_y_32gf',\n 'regnet_y_3_2gf',\n 'regnet_y_400mf',\n 'regnet_y_800mf',\n 'regnet_y_8gf',\n 'resnet101',\n 'resnet152',\n 'resnet18',\n 'resnet34',\n 'resnet50',\n 'resnext101_32x8d',\n 'resnext101_64x4d',\n 'resnext50_32x4d',\n 's3d',\n 'shufflenet_v2_x0_5',\n 'shufflenet_v2_x1_0',\n 'shufflenet_v2_x1_5',\n 'shufflenet_v2_x2_0',\n 'squeezenet1_0',\n 'squeezenet1_1',\n 'swin3d_b',\n 'swin3d_s',\n 'swin3d_t',\n 'swin_b',\n 'swin_s',\n 'swin_t',\n 'swin_v2_b',\n 'swin_v2_s',\n 'swin_v2_t',\n 'vgg11',\n 'vgg11_bn',\n 'vgg13',\n 'vgg13_bn',\n 'vgg16',\n 'vgg16_bn',\n 'vgg19',\n 'vgg19_bn',\n 'vit_b_16',\n 'vit_b_32',\n 'vit_h_14',\n 'vit_l_16',\n 'vit_l_32',\n 'wide_resnet101_2',\n 'wide_resnet50_2']"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hub.list('pytorch/vision')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T15:07:48.751116Z",
     "start_time": "2023-10-23T15:07:40.191467Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
